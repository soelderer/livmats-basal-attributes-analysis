---
title: "Data preperation part II of basal attributes article"
author: "Julius Fenn, Paul Sölder"
format:
  html:
    toc: true
    toc-depth: 3
    html-math-method: katex
    number-sections: true
---


# Notes


# create raw data files



```{r}
#| label: create raw files
#| warning: false

# sets the directory of location of this script as the current directory
# setwd(dirname(rstudioapi::getSourceEditorContext()$path))

### load packages
require(pacman)
p_load('tidyverse', 'jsonlite', 'magrittr', 'xlsx',
       'stargazer', 'psych', 'jtools', 'DT', 'ggstatsplot', 
       'lavaan', 
       'regsem', 'MplusAutomation', 'igraph')

### list data files
setwd("data")
folders <- list.files(pattern = "^study_result.*")

### create data files
### get CAM data
writeLines("", "CAMdata.txt") # create file
text_connection <- file("CAMdata.txt", "a") # open connection to append

### get pre CAM data
writeLines("", "preCAM.txt") # create file
text_connection_pre <- file("preCAM.txt", "a") # open connection to append

### get post CAM data
writeLines("", "postCAM.txt") # create file
text_connection_post <- file("postCAM.txt", "a") # open connection to append

for(i in 1:length(folders)){
  setwd(folders[i])
  if(length(dir()) == 3){
    # print(i)
    ### CAM data
    setwd(dir()[2])
    tmp <- jsonlite::fromJSON(txt = "data.txt")
    writeLines(jsonlite::toJSON(x = tmp), text_connection)
    setwd("..")

    ### pre CAM data
    setwd(dir()[1])
    tmp <- jsonlite::fromJSON(txt = "data.txt")
    writeLines(jsonlite::toJSON(x = tmp), text_connection_pre)
    setwd("..")

    ### post CAM data
    setwd(dir()[3])
    tmp <- jsonlite::fromJSON(txt = "data.txt")
    writeLines(jsonlite::toJSON(x = tmp), text_connection_post)
    setwd("..")
  }
  setwd("..")
}

close(text_connection) # close connection CAM
close(text_connection_pre) # close connection
close(text_connection_post) # close connection

### move files to output folder
# copy files (not overwritten)
tmp_file_from <-  getwd()
setwd("../outputs/01_dataPreperation")
file.copy(from =  paste0(tmp_file_from, "/CAMdata.txt"), to = paste0(getwd(), "/CAMdata.txt"))
file.copy(from =  paste0(tmp_file_from, "/preCAM.txt"), to = paste0(getwd(), "/preCAM.txt"))
file.copy(from =  paste0(tmp_file_from, "/postCAM.txt"), to = paste0(getwd(), "/postCAM.txt"))

### remove files
file.remove(paste0(tmp_file_from, "/CAMdata.txt"))
file.remove(paste0(tmp_file_from, "/preCAM.txt"))
file.remove(paste0(tmp_file_from, "/postCAM.txt"))


### load functions
setwd("../../functions")
for(i in 1:length(dir())){
  # print(dir()[i])
  source(dir()[i], encoding = "utf-8")
}


setwd("../functions_CAMapp")
for(i in 1:length(dir())){
  # print(dir()[i])
  source(dir()[i], encoding = "utf-8")
}
rm(i)



### summary function
data_summary <- function(data, varname, groupnames){
  require(plyr)
  summary_func <- function(x, col){
    c(mean = mean(x[[col]], na.rm=TRUE),
      se = sd(x[[col]], na.rm=TRUE) / sqrt(length(x[[col]])))
  }
  data_sum<-ddply(data, groupnames, .fun=summary_func,
                  varname)
  data_sum <- plyr::rename(data_sum, c("mean" = varname))
  return(data_sum)
}
```


# set up data.frame questionnaires


```{r}
#| label: create questionnaires files
#| warning: false

setwd("outputs/01_dataPreperation")
# > pre study
suppressMessages(read_file('preCAM.txt') %>%
                   # ... split it into lines ...
                   str_split('\n') %>% first() %>%
                   # ... filter empty rows ...
                   discard(function(x) x == '') %>%
                   discard(function(x) x == '\r') %>%
                   # ... parse JSON into a data.frame
                   map_dfr(fromJSON, flatten=TRUE)) -> dat_preCAM
# > post CAM
read_file('postCAM.txt') %>%
                   # ... split it into lines ...
                   str_split('\n') %>% first() %>%
                   # ... filter empty rows ...
                   discard(function(x) x == '') %>%
                   discard(function(x) x == '\r') -> tmp_postCAM


tmp_out <- list()
for(i in 1:length(tmp_postCAM)){
tmp_out[[i]] <- fromJSON(tmp_postCAM[i])
tmp_out[[i]]$"21" <- NULL # causes error
}

dat_postCAM <- dplyr::bind_rows(tmp_out)
rm(tmp_postCAM); rm(tmp_out)



### create counter variable for both data sets
# > pre study
dat_preCAM$ID <- NA

tmp_IDcounter <- 0
for(i in 1:nrow(dat_preCAM)){
  if(!is.na(dat_preCAM$sender[i]) && dat_preCAM$sender[i] == "Greetings"){
    # tmp <- dat_preCAM$prolific_pid[i]
    tmp_IDcounter = tmp_IDcounter + 1
  }
  dat_preCAM$ID[i] <- tmp_IDcounter
}

# > post CAM
dat_postCAM$ID <- NA

tmp_IDcounter <- 0
for(i in 1:nrow(dat_postCAM)){
  if(!is.na(dat_postCAM$sender[i]) && dat_postCAM$sender[i] == "CAMfeedbackGeneral"){
    # tmp <- dat_postCAM$prolific_pid[i]
    tmp_IDcounter = tmp_IDcounter + 1
  }
  dat_postCAM$ID[i] <- tmp_IDcounter
}



### keep only complete data sets
# > pre study
# sort(table(dat_preCAM$ID))
sum(table(dat_preCAM$ID) != max(table(dat_preCAM$ID)))
sum(table(dat_preCAM$ID) == max(table(dat_preCAM$ID)))

dat_preCAM <- dat_preCAM[dat_preCAM$ID %in% names(table(dat_preCAM$ID))[table(dat_preCAM$ID) == max(table(dat_preCAM$ID))],]

# > post CAM
# sort(table(dat_postCAM$ID))
sum(table(dat_postCAM$ID) != max(table(dat_postCAM$ID)))
sum(table(dat_postCAM$ID) == max(table(dat_postCAM$ID)))


dat_postCAM <- dat_postCAM[dat_postCAM$ID %in% names(table(dat_postCAM$ID))[table(dat_postCAM$ID) == max(table(dat_postCAM$ID))],]



### json (from JATOS) to 2D data.frame
# > pre study
# add paradata
tmp_notNumeric <- str_subset(string = colnames(dat_preCAM), pattern = "^meta|^R")
tmp_notNumeric <- str_subset(string = tmp_notNumeric, pattern = "labjs|location", negate = TRUE)

### get survey
vec_ques <- c("PROLIFIC_PID",
              "dummy_informedconsent", 
              "commCheck",
              tmp_notNumeric)

vec_notNumeric = c("PROLIFIC_PID", tmp_notNumeric)

questionnaire_preCAM <- questionnairetype(dataset = dat_preCAM, 
                                        listvars = vec_ques, 
                                        notNumeric = vec_notNumeric, verbose = FALSE)

dim(questionnaire_preCAM)



# > post CAM
tmp_numeric <- str_subset(string = colnames(dat_postCAM), pattern = "^nfc")


vec_ques <- c("PROLIFIC_PID", "commCheck",
              "feedCAM_repres", "feedCAM_technicalprobs", "feedCAM_technicalprobsText", "feedCAM_already","feedCAM_alreadyText",
              "openQuestion_MaterialSystem",
              "openQuestion_Ethic",
              "openQuestion_missedPositive", "openQuestion_missedNegative",
              "outcome_research", "outcome_prohibition", "outcome_buy", "outcome_buy_text", 
              "education", "experienceMS",
              tmp_numeric,
              "feedback_critic")

     

vec_notNumeric = c("PROLIFIC_PID", 
                   "feedCAM_technicalprobsText", "feedCAM_alreadyText", 
                                 "openQuestion_MaterialSystem",
                                 "openQuestion_Ethic",
              "openQuestion_missedPositive", "openQuestion_missedNegative",
   "outcome_research", "outcome_prohibition", "outcome_buy", "outcome_buy_text", 
                   "education", "experienceMS",
                   "feedback_critic")

questionnaire_postCAM <- questionnairetype(dataset = dat_postCAM,
                                        listvars = vec_ques,
                                        notNumeric = vec_notNumeric, verbose = FALSE)

questionnaire_postCAM$feedback_critic[questionnaire_postCAM$feedback_critic == ""] <- NA
dim(questionnaire_postCAM)


questionnaire_postCAM$multipleEthic <- NA
tmp_multipleEthic <- cbind(dat_postCAM$ID, dat_postCAM$multipleEthic)

questionnaire_postCAM$multiplePositive <- NA
tmp_multiplePositive <- cbind(dat_postCAM$ID, dat_postCAM$multiplePositive)

questionnaire_postCAM$multipleNegative <- NA
tmp_multipleNegative <- cbind(dat_postCAM$ID, dat_postCAM$multipleNegative)


for(i in questionnaire_postCAM$ID){
  # add multipleEthic
  tmp <- tmp_multipleEthic[tmp_multipleEthic[,1] == i, ]
  if(length(unlist(tmp[,2])) == 3){
    questionnaire_postCAM$multipleEthic[questionnaire_postCAM$ID == i] <- paste0(unlist(tmp[,2]), collapse = " \\ ")
  }
  
  # add multiplePositive
    tmp <- tmp_multiplePositive[tmp_multiplePositive[,1] == i, ]
  if(length(unlist(tmp[,2])) == 3){
    questionnaire_postCAM$multiplePositive[questionnaire_postCAM$ID == i] <- paste0(unlist(tmp[,2]), collapse = " \\ ")
  }
    
      # add multipleNegative
    tmp <- tmp_multipleNegative[tmp_multipleNegative[,1] == i, ]
  if(length(unlist(tmp[,2])) == 3){
    questionnaire_postCAM$multipleNegative[questionnaire_postCAM$ID == i] <- paste0(unlist(tmp[,2]), collapse = " \\ ")
  }
}


dim(questionnaire_postCAM)



### merge all data sets
# remove one missing
questionnaire_preCAM <- questionnaire_preCAM[questionnaire_preCAM$PROLIFIC_PID %in% questionnaire_postCAM$PROLIFIC_PID, ]


questionnaire_postCAM$ID <- NULL
questionnaire <- left_join(questionnaire_preCAM, questionnaire_postCAM, by="PROLIFIC_PID")


## all missing answers to NA
questionnaire[questionnaire == ""] <- NA
## all feedback smaller than 3 characters to NA
questionnaire$feedback_critic[nchar(questionnaire$feedback_critic) <= 2] <- NA

dim(questionnaire)


### save files
## save as .xlsx file
xlsx::write.xlsx2(x = questionnaire, file = "questionnaire.xlsx")
## save as R object
saveRDS(questionnaire, file = "questionnaire.rds")
```

# get reaction times for single components

Plot time taken (in minutes) by participants for single components of study:

```{r, message = FALSE}
#| label: get reaction times by component

dat_duration <- data.frame(duration = NA, sender = NA, ID = NA, PROLIFIC_PID = NA)



for(i in 1:length(unique(dat_preCAM$ID))){

  tmp_PID <- dat_preCAM$PROLIFIC_PID[dat_preCAM$ID ==  unique(dat_preCAM$ID)[i] & !is.na(dat_preCAM$PROLIFIC_PID)]
  
  

     # pre CAM
    tmp_preCAM <- data.frame(duration = dat_preCAM$duration[dat_preCAM$ID == unique(dat_preCAM$ID)[i]] / 1000,
                    sender = dat_preCAM$sender[dat_preCAM$ID == unique(dat_preCAM$ID)[i]])
    tmp_preCAM <- tmp_preCAM[!is.na(tmp_preCAM$sender),]
    
     # post CAM
    tmp_postCAM <- data.frame(duration = dat_postCAM$duration[dat_postCAM$ID == unique(dat_postCAM$ID)[i]] / 1000,
                    sender = dat_postCAM$sender[dat_postCAM$ID == unique(dat_postCAM$ID)[i]])
    tmp_postCAM <- tmp_postCAM[!is.na(tmp_postCAM$sender),]
    
  
    tmp <- rbind(tmp_preCAM, tmp_postCAM)
    

  if(all(is.na(dat_duration))){
    dat_duration <- data.frame(duration = tmp$duration,
                              sender = tmp$sender,
                              ID = rep(i, times=nrow(tmp)),
                              PROLIFIC_PID = rep(tmp_PID, times=nrow(tmp)))


  }else{
    dat_duration <- rbind(dat_duration,  data.frame(duration = tmp$duration,
                                                    sender = tmp$sender,
                                                    ID = rep(i, times=nrow(tmp)),
                                                    PROLIFIC_PID = rep(tmp_PID, times=nrow(tmp))))
  }
}

## remove empty sender 
dat_duration <- dat_duration[!is.na(dat_duration$sender), ]
dat_duration <- dat_duration[!is.na(dat_duration$duration), ]

dat_duration$sender[dat_duration$sender == "done"] <- "CAM instructions"

## save as .xlsx
# write.xlsx2(x = dat_duration, file = "outputs/para_duration_singleComponents.xlsx")

#### plot
dat_duration$ID <- factor(dat_duration$ID)
p <- dat_duration %>%
  ggplot(aes(x=sender, y=duration, color=PROLIFIC_PID)) +
  geom_point() +
  geom_jitter(width=0.15)+
  theme(axis.text.x = element_text(angle = 90)) + theme(legend.position="none")
p

## save ggplot as PDF
ggsave(filename = "outputs/01_dataPreperation/durations_components.pdf", p)


# Calculate the mean duration in seconds for each sender and sort by mean duration
tmp <- dat_duration %>%
  group_by(sender) %>%
  summarise(N = n(), mean_duration = mean(duration, na.rm = TRUE)) %>%
  arrange(desc(mean_duration))
DT::datatable(tmp, options = list(pageLength = 5)) 
```


## set up CAM data

Load CAM data

```{r, message = FALSE}
#| label: get raw CAM data pre

setwd("outputs/01_dataPreperation")
suppressMessages(read_file("CAMdata.txt") %>%
  # ... split it into lines ...
  str_split('\n') %>% first() %>%
    discard(function(x) x == '') %>%
    discard(function(x) x == '\r') %>%
  # ... filter empty rows ...
  discard(function(x) x == '')) -> dat_CAM_pre

raw_CAM <- list()
for(i in 1:length(dat_CAM_pre)){
  raw_CAM[[i]] <- jsonlite::fromJSON(txt = dat_CAM_pre[[i]])
}
```

Create CAM files, draw CAMs and compute network indicators

```{r, message = FALSE}
#| label: draw CAMs, network indicators, wordlist

### create CAM single files (nodes, connectors, merged)
CAMfiles <- create_CAMfiles(datCAM = raw_CAM, reDeleted = TRUE)


# remove testing data sets
CAMfiles[[1]] <- CAMfiles[[1]][CAMfiles[[1]]$participantCAM %in% questionnaire$PROLIFIC_PID,]
CAMfiles[[2]] <- CAMfiles[[2]][CAMfiles[[2]]$participantCAM %in% questionnaire$PROLIFIC_PID,]
CAMfiles[[3]] <- CAMfiles[[3]][CAMfiles[[3]]$participantCAM.x %in% questionnaire$PROLIFIC_PID,]

### draw CAMs
CAMdrawn <- draw_CAM(dat_merged = CAMfiles[[3]],
                     dat_nodes = CAMfiles[[1]],ids_CAMs = "all",
                     plot_CAM = FALSE,
                     useCoordinates = TRUE,
                     relvertexsize = 3,
                     reledgesize = 1)

### network indicators
tmp_microIndicator <- V(CAMdrawn[[1]])$label
networkIndicators <- compute_indicatorsCAM(drawn_CAM = CAMdrawn, 
                                           micro_degree = tmp_microIndicator, 
                                           micro_valence = tmp_microIndicator, 
                                           micro_centr_clo = tmp_microIndicator, 
                                           micro_transitivity = tmp_microIndicator, 
                                           largestClique = FALSE)


### wordlist
CAMwordlist <- create_wordlist(
  dat_nodes =  CAMfiles[[1]],
  dat_merged =  CAMfiles[[3]],
  useSummarized = TRUE,
  order = "frequency",
  splitByValence = FALSE,
  comments = TRUE,
  raterSubsetWords = NULL,
  rater = FALSE
)

DT::datatable(CAMwordlist, options = list(pageLength = 5))
```


### plot CAMs using igraph package

Just plot first 10 CAMs for an impression

```{r}
#| label: draw first 10 CAMs

for(i in 1:10){ # length(CAMdrawn)
  plot(CAMdrawn[[i]], edge.arrow.size = .7,
       layout=layout_nicely, vertex.frame.color="black", asp = .5, margin = -0.1,
       vertex.size = 10, vertex.label.cex = .9)
}
```



### save CAMs as .json files, and as .png (igraph)


```{r saveCAMs_pictures_pre, message = FALSE}
#| label: save CAM pictures

save_CAMs_as_pictures = FALSE

if(save_CAMs_as_pictures){
setwd("outputs/01_dataPreperation")

setwd("savedCAMs")
setwd("png")
### remove all files if there are any
if(length(list.files()) >= 1){
  file.remove(list.files())
  cat('\n!
      all former .png files have been deleted')
}

### if no participant ID was provided replace by randomly generated CAM ID
if(all(CAMfiles[[3]]$participantCAM.x == "noID")){
  CAMfiles[[3]]$participantCAM.x <- CAMfiles[[3]]$CAM.x
}

### save as .json files, and as .png (igraph)
ids_CAMs <- unique(CAMfiles[[3]]$participantCAM.x); length(ids_CAMs)


for(i in 1:length(ids_CAMs)){
  save_graphic(filename = paste0("CAM", ids_CAMs[i])) #  paste0(ids_CAMs[i]))
  CAM_igraph <- CAMdrawn[[c(1:length(CAMdrawn))[
    names(CAMdrawn) == paste0(unique(CAMfiles[[3]]$participantCAM.x)[i])]]]
  plot(CAM_igraph, edge.arrow.size = .7,
       layout=layout_nicely, vertex.frame.color="black", asp = .5, margin = -0.1,
       vertex.size = 10, vertex.label.cex = .9)
  dev.off()
}

setwd("../json")
### remove all files if there are any
if(length(list.files()) >= 1){
  file.remove(list.files())
  cat('\n!
      all former .json files have been deleted')
}
for(i in 1:length(raw_CAM)){
  if(!is_empty(raw_CAM[[i]]$nodes)){
    if(nrow(raw_CAM[[i]]$nodes) > 5){
      if(raw_CAM[[i]]$creator %in% questionnaire$PROLIFIC_PID){ # only if not deleted previously
              write(toJSON(raw_CAM[[i]], encoding = "UTF-8"),
            paste0(raw_CAM[[i]]$creator, ".json"))
      }
    }
  }
}
}
```




### delete CAMs with strong star topology

```{r}
#| label: delete CAMs

barplot(table(networkIndicators$degreetot_micro_AkzeptanzeinesneuenMaterialsystems) / nrow(networkIndicators))

for(i in 1:nrow(networkIndicators)){
  if(networkIndicators$degreetot_micro_AkzeptanzeinesneuenMaterialsystems[i] == 32){
      plot(CAMdrawn[[i]], edge.arrow.size = .7,
       layout=layout_nicely, vertex.frame.color="black", asp = .5, margin = -0.1,
       vertex.size = 10, vertex.label.cex = .9)
  }
}
```






### plot aggregated CAM

```{r}
#| label: aggregate CAMs

sel_ids <- unique(CAMfiles[[1]]$participantCAM)
CAMaggregated <- aggregate_CAMs(dat_merged = CAMfiles[[3]], dat_nodes = CAMfiles[[1]],
                                ids_CAMs = sel_ids)

# plot(CAMaggregated[[2]], vertex.size=diag(CAMaggregated[[1]]) / max(diag(CAMaggregated[[1]]))*20, edge.arrow.size=0.01)
# plot(CAMaggregated[[2]], vertex.size=(abs(V(CAMaggregated[[2]])$value)+1)*5, edge.arrow.size=0.01)


g = CAMaggregated[[2]]
g2 = simplify(CAMaggregated[[2]])
# plot(g2, edge.arrow.size=0.01,
#      vertex.size=diag(CAMaggregated[[1]]) / max(diag(CAMaggregated[[1]]))*20)

E(g2)$weight = sapply(E(g2), function(e) {
  length(all_shortest_paths(g, from=ends(g2, e)[1], to=ends(g2, e)[2])$res) } )
E(g2)$weight = E(g2)$weight * 2
# E(g2)$weight[E(g2)$weight == 1] <- NA

V(g2)$color[V(g2)$value <= .5 & V(g2)$value >= -.5] <- "yellow"

V(g2)$shape <- NA
V(g2)$shape <- ifelse(test = V(g2)$color == "yellow", yes = "square", no = "circle")



### > plot multiple times because of random layout
for(i in 1:3){
  plot(g2, edge.arrow.size = 0,
     layout=layout_nicely, vertex.frame.color="black", asp = .5, margin = -0.1,
     vertex.size=diag(CAMaggregated[[1]]) / max(diag(CAMaggregated[[1]]))*5,
     vertex.label.cex = .9, 
     edge.weight=2, edge.width=(E(g2)$weight/35))
}



CAMaggregated[[1]][1:5, 1:5]
```






# analyze data

## describe data set

### feedback to the study

Question: 

```{r}
#| label: feedback critic

DT::datatable(questionnaire[!is.na(questionnaire$feedback_critic),c("PROLIFIC_PID", "feedback_critic")], options = list(pageLength = 5)) 
```

### Material system that has been thought of

Question:  Bitte beschreiben Sie an an welches Materialsystem oder welche Materialsysteme Sie dabei gedacht haben. 

```{r}
#| label: material thought of

DT::datatable(questionnaire[,c("PROLIFIC_PID", "openQuestion_MaterialSystem")], options = list(pageLength = 5)) 
```

### basal attributes: most pos. / neg.

Question: Welche drei Begriffen nehmen Sie am positivsten bzw. negativsten für die Beschreibung neuer Materialsysteme wahr?


```{r}
#| label: most pos, most neg

## most positive
tmp <- str_trim(unlist(str_split(string = questionnaire$multiplePositive, pattern = "\\\\")))
sort(table(tmp))

## most negative
tmp <- str_trim(unlist(str_split(string = questionnaire$multipleNegative, pattern = "\\\\")))
sort(table(tmp))

## answers of participants
DT::datatable(questionnaire[,c("PROLIFIC_PID", "multiplePositive", "multipleNegative")], options = list(pageLength = 5)) 
```


**any basal attributes missing?**

Question:  Fallen Ihnen weitere Eigenschaften ein, die Sie als relevant oder negativ für die Beschreibung neuer Materialsysteme erachten, die in der Liste nicht aufgeführt sind, so können Sie diese gerne in folgenden Textfeldern ergänzen: 


```{r}
#| label: basal attribute missing

## answers of participants
DT::datatable(questionnaire[,c("PROLIFIC_PID", "openQuestion_missedPositive", "openQuestion_missedNegative")], options = list(pageLength = 5)) 
```



### basal attributes: ethical most relevant

Question:  Welche drei Begriffe sind aus Ihrer Sicht in moralischer Hinsicht am "relevantesten"?


```{r}
#| label: ethical relevant

## ethical relevant
tmp <- str_trim(unlist(str_split(string = questionnaire$multipleEthic, pattern = "\\\\")))
sort(table(tmp))

## answers of participants
DT::datatable(questionnaire[,c("PROLIFIC_PID", "multipleEthic")], options = list(pageLength = 5)) 
```

**argument for choosen basal attributes**

Question: Bitte begründen Sie kurz die Auswahl der ethisch relevanten Begriffe:


```{r}
#| label: argument ethical relevant

## answers of participants
DT::datatable(questionnaire[,c("PROLIFIC_PID", "openQuestion_Ethic")], options = list(pageLength = 5)) 
```


### outcome questions

Question: Sollte die Entwicklung innovativer Materialsysteme mit öffentlichen Mitteln gefördert werden? 	

```{r}
#| label: outcome research

table(questionnaire$outcome_research)
```

Question: Sollten die Erforschung und Entwicklung solcher innovativer Materialsysteme verboten werden?

```{r}
#| label: outcome prohibition

table(questionnaire$outcome_prohibition)
```

Question: Wären Sie bereit, Produkte zu kaufen, die innovative Materialsysteme enthalten? 


```{r}
#| label: outcome buy

table(questionnaire$outcome_buy)
```

> if yes to previous question

Question: An welche möglichen Produkte haben Sie gedacht? 

```{r}
#| label: outcome buy - text
#| 
## answers of participants
DT::datatable(questionnaire[,c("PROLIFIC_PID", "outcome_buy_text")], options = list(pageLength = 5)) 
```

 	
## co-variation of basal attributes

Compare the probability that two concepts are connected in randomly generated networks to drawn CAMs:

```{r}
## get average number of drawn concepts (here fixed)
numConcepts <- mean(networkIndicators$num_nodes_macro)
## get average density
numDensity <- mean(networkIndicators$density_macro)

## simply get the average probability that two concepts are connected:
g <- igraph::random.graph.game(n = numConcepts, p.or.m = numDensity)
plot(g)
are.connected(g, 1, 2)


#> whereby each edge to be drawn has the identical probability in the Erdős–Rényi model
vec_booleanConnected <- c()
# vec_booleanConnected2 <- c()

for(i in 1:10000){
  g <- igraph::random.graph.game(n = numConcepts, p.or.m = numDensity)
  vec_booleanConnected[i] <- are.connected(g, 1, 2)
    # vec_booleanConnected2[i] <- are.connected(g, 22, 26)
}
baselineProbability <- mean(vec_booleanConnected)
baselineProbability
# mean(vec_booleanConnected2)
```

This baseline probability can be compared to all possible combinations of drawn concepts: 

```{r}
vec_boolean <- c()
for(i in 1:length(CAMdrawn)){
  vec_boolean[i] <- are.connected(graph = CAMdrawn[[i]], 
              v1 = V(CAMdrawn[[i]])[V(CAMdrawn[[i]])$label == "robust"], 
              v2 = V(CAMdrawn[[i]])[V(CAMdrawn[[i]])$label == "widerstandsfähig"])
}

mean(vec_boolean)
```


